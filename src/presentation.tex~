% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This file is a template using the "beamer" package to create slides for a talk or presentation
% - Giving a talk on some subject.
% - The talk is between 15min and 45min long.
% - Style is ornate.

% MODIFIED by Jonathan Kew, 2008-07-06
% The header comments and encoding in this file were modified for inclusion with TeXworks.
% The content is otherwise unchanged from the original distributed with the beamer package.

\documentclass{beamer}

\usepackage{graphicx}

% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 


\mode<presentation>
{
  \usetheme{Warsaw}
  % or ...

  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[english]{babel}
% or whatever

\usepackage[utf8]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title[Team Reverwesome: Othello Bot] % (optional, use only with long paper titles)
{COMP3130 Othello Project}

\subtitle
{Team Reverwesome} % (optional)

\author[Josh Godsiff, Jarrah Bloomfield] % (optional, use only with lots of authors)
{~Josh Godsiff \and ~Jarrah Bloomfield}
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\date[Short Occasion] % (optional)
{May 29th, 2012}

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Problem Outline}
    \begin{itemize}
  \item
    Modified Othello Game
  \item
    4 randomly removed squares
  \item
    10x10 board rather than the traditional 8x8
  \item
    Network communication with server
  \item
    150 seconds total time per player
  \item
    Design an agent to play intelligently
  \end{itemize}
\end{frame}

\begin{frame}{Solution Outline}
    \begin{itemize}
  \item
    Static evaluation function based on feature weights
  \item
    Temporal Difference Learning
  \item
    Negamax search with alpha beta pruning
  \item
    Concurrent searching
  \item
    Time management
  \end{itemize}
\end{frame}

\begin{frame}{Static Evaluation}
    \begin{itemize}
  \item
    Use features weights to evaluate value of board states
  \item
    15 weights for each piece position
	\begin{itemize}
		\item based on (naive) 8-way symmetry
		\item in actuality, only a 4-way symmetry exists. However, in practice this doesn't make a lot of difference.
		% Include picture showing the difference?
	\end{itemize}
  \item
    Weight for mobility - number of moves if it was our turn
  \item
   Weight for stability - number of stable pieces we own
  \item
   Weight for internals - number of internal pieces we own
  \end{itemize}
\end{frame}

\begin{frame}{Piece Stability}
    \begin{itemize}
  \item
  Stability is the inability for a piece to ever be flipped. For example, corners are always stable.
  \item
   All 4 lines must be stable in one direction
  \item
   Line stability from the whole line being 'full'
  \item
   Line stability from the whole direction being stable and full in your favour
  \end{itemize}

\end{frame}

\begin{frame}{Piece Stability}
\begin{center}
\includegraphics[scale=0.50]{stability.PNG}\\
Stable positions for white
\end{center}
\end{frame}

\begin{frame}{Piece Internality}
    \begin{itemize}
  \item
  A piece is internal if it has no empty neighbours
  \item
   Harder to dislodge, can result in higher mobility
  \end{itemize}
\end{frame}

\begin{frame}{Temporal Difference Learning}
   \begin{itemize}
  \item
  	Used a fairly standard TD($\lambda$) policy.
  \item
	Play whole game, recieve reward $r\in \left\{1,0,-1 \right\}$ for win/draw/loss.
  \item
	For each board $b_k$ position in the game, find the direction to adjust the weight in, based on making a small change and seeing if it improves/worsens the result.
 \item
	Then run through all of it is successors, and calculate the weighted difference between it's value and the successor's.
  \item
	$\sum_{t=k}^T \lambda^t \left ( V(b_t) - V(b_k) + feedback \right)$
  \end{itemize}
\end{frame}

\begin{frame}{Learning Strategies}
\begin{itemize}
	\item $\alpha = 0.0001$
		\\ Learning weight. Tend to get divergence if we set it any higher.
	
	\item $\epsilon = 0.15$
		\\ Used for $\epsilon$-greedy policy. The chance we'll pick a random move instead of a good one.
	\item $\gamma = 0.9$
		\\ Discount factor on how much we weight boards far into the 'future' when training.
		\\ Scales as $\gamma^t$, where $t$ is the number of boards in the futre we're looking.
	\end{itemize}
\end{frame}

\begin{frame}{Negamax with alpha beta pruning}
    \begin{itemize}
  \item
    Adversarial search algorithm
  \item
    Minmax algorithm modified to negate the value at each step
  \item
    Attempts to maximise reward against adversary who is actively minimising reward
  \item
   $\alpha$ - $\beta$ pruning cuts sections of the game tree that an opponent would never choose
  \end{itemize}
\end{frame}

\begin{frame}{Negamax features}
    \begin{itemize}
  \item
    Search to a moderate depth if close to the start of the game
  \item
    Search to a deep depth if close to the end of the game
  \item
    Add depth if exploring along a forced move
  \item
    Use static evaluation feature weights to evaluate how far in our favour the board value is
  \item
    Terminals in our favour worth $\infty$, in opponent's favour worth $-\infty$.
  \end{itemize}
\end{frame}

\begin{frame}{Concurrency}
    \begin{itemize}
  \item
	Use concurrency to distribute MinMax search across multiple CPUs, thereby (hopefully) reducing the time taken for a search.
 \item
	Have to find a model of parallelism which balances putting processing time where it's needed vs overhead in communication between threads.
 \item
	We settled for a simplistic model - give each thread one of the 'top-level' MinMax nodes to search through. When it's done, give it another one.
 \item
	Has the downside that $\alpha \beta$ pruning data does not get updated until a thread finishes its node.
 \item
	Initial nodes can take more time than they otherwise might have.
 \item
	But still end up with an $O(n)$ speed up, where $n$ is the number of cores.
  \end{itemize}
\end{frame}

\begin{frame}{Time management}
    \begin{itemize}
  \item
    Vary the search depth depending on time left and how long the previous move took
  \item
    Below 15 seconds, drop to depth 4
  \item
     Below 5 seconds, drop to depth 2  
  \end{itemize}
\end{frame}

\begin{frame}{Key Observations}
    \begin{itemize}
  \item
    Because of the removed squares, piece stability became especially important ahead
  \end{itemize}
\end{frame}

\begin{frame}{Other ideas (Monte Carlo)}
    \begin{itemize}
  \item
    	Use monte carlo prediction as a substitute for reward to help with learning of mid-game states
  \item
	Tends to make the algorithm learn more quickly, and on-the-fly
  \item
	Can also be used as a predictor of how good a board state is.
  \end{itemize}
\end{frame}

\begin{frame}{Other ideas (MinMax)}
    \begin{itemize}
  \item
    Optimised search ordering - expand nodes by their value in our piece feature weights
  \item
	Store searches between moves. Could have saved a huge amount of computation time.
  \item
	Vary depth of search based on branching factor and volatility of the state.
  \end{itemize}
\end{frame}

\begin{frame}{Other ideas (Evolutionary Algorithm)}
    \begin{itemize}
  \item
   	Use an evolutionary algorithm strategy to play agents off against each other.
  \item
	Use feature values as 'genes'.
  \item
	'Breeding' via exchanging features. Don't need a heuristic for which to exchange, as features tend to be relatively independent.
  \item
	Mutation via small random change to a feature.
	\\ e.g. from a uniform distribution around (-1,1), or
	\\ Normal distribution with mean 0.
  \item
	Essentially still doing gradient decent. Can be used as a substitute for an $\epsilon$-greedy policy.
  \end{itemize}
\end{frame}

\begin{frame}{Winning Speech}
    \begin{itemize}
  \item
    Friends, family, wives, pets, neighbours etc.
  \item
   Beyonce has one of the greatest videos of all time. Of all time!
  \item
   Won despite our handicap being the only group to not have an Andrew
  \item
   Other groups played well but we can't all be winners
  \end{itemize}
\end{frame}

\end{document} 